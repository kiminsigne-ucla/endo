---
title: "Endogenous TSS scramble library mapping"
output:
  html_document:
    df_print: paged
---

```{r, echo = F, include = F}
setwd("~/Documents/projects/ecoli_promoters/endo/scripts/endo_scramble")
options(stringsAsFactors = F)
options(scipen = 10000)
library(dplyr)
library(tidyr)
library(cowplot)
library(ggplot2)

bc_stats <- read.table('../../processed_data/endo_scramble/endo_scramble_mapping_barcode_statistics.txt',
                       sep = '\t', header = T)

var_stats <- read.table('../../processed_data/endo_scramble/endo_scramble_mapping_variant_statistics.txt',
                       sep = '\t', header = T)

ref <- read.table('../../ref/20180507_active_tss_scrambled10_stride5.txt', sep = '\t',
                  col.names = c('name', 'sequence')) %>% 
    mutate(variant = substr(sequence, 25, 174))
```

Mapping results:
```
Number of reads: 29997877
Reading in library reference...
Extracting perfect reads...
Percent perfect: 0.169511329085
Number of unique barcodes for perfect reads:  1632913
Filter by barcode frequency...
Number of barcodes > 2: 749914
Mapping...
Bootstrapping reference sequences to obtain cutoff... cutoff is Levenshtein distance  74.0
Filtering and writing results...
Percent of library represented by final barcodes: 0.990981449387
Number of final barcodes:  744936
```


How many unique barcodes per variant?
```{r, echo = F}
ggplot(var_stats, aes(num_barcodes_unique)) + geom_histogram(binwidth = 1) +
    geom_vline(xintercept = median(var_stats$num_barcodes_unique), linetype = 'dashed') +
    labs(x = 'number of unique barcodes per variant')
```

```{r, echo = F}
summary(var_stats$num_barcodes_unique)
```


What is the number of reads per variant (aka number of non-unique barcodes)?
```{r, echo = F}
ggplot(var_stats, aes(num_barcodes)) + geom_histogram(binwidth = 1) +
    labs(x = 'number of reads per variant')
```


```{r, echo = F}
summary(var_stats$num_barcodes)
```

How many reads per barcode?

```{r, echo = F}
ggplot(bc_stats, aes(num_reads)) + geom_histogram(binwidth = 1) + 
    geom_vline(xintercept = median(bc_stats$num_reads), linetype = 'dashed') +
    scale_x_continuous(limits = c(0, 100)) +
    labs(x = 'number of reads per barcode')
```

```{r, echo = F}
summary(bc_stats$num_reads)
```

Let's read in the results of barcode mapping using Nate's mapper, which generates a consensus
read for each barcode instead of just looking at perfects.

```
python bc-map.py ../../processed_data/endo_scramble/endo_scramble_merged.fastq ../../ref/20180507_active_tss_scrambled10_stride5_trimmed.fasta --bc-start -20 --bc-length 20 --proc 30 --ver
bose --bbmap-procs 30 --var_start 1 --var_length 150 --min-reads 3 --bad-bcs bc-map_bad_bcs.txt > bc-map_results.txt                                                                                                                                
Mapping BCs...
Mapped 6017579 barcodes in 252.71 seconds
Filtering BCs without a consensus of < 3 reads
Found 3077822 BCs with < 3 reads in 20.69 secs
Using BBMap to find contaminated barcodes at 5 away
Mapped barcodes in 439.58 secs
Found 9543 barcodes that map too far away in 13.88 secs
Found 933 truncated barcodes in 60.15 secs
Found 453 barcodes with at least one sequence at dist 4 with at least 2 reads in 23.17 secs
Merged reads in 149.79 seconds
Total BCs remaining after filters 2928828
Total time 16.00 mins
Wrote 3088751 barcodes in 11.78 secs

```

- Lose 62.7% of barcodes when filtering for barcodes with at least 5 reads. I changed it to 
3 reads and gained 696062
- Next step, lose 7.8% to contaminated barcodes


```{r}
bc_map <- read.table('bc-map_results.txt', sep = ',', header = F,
                     col.names = c('barcode', 'variant', 'count'))
```

```{r}
ggplot(bc_map, aes(count)) + geom_histogram(binwidth = 1) +
    labs(x = 'number of reads per barcode')
```

```{r}
summary(bc_map$count)
```

```{r}
var_stats_new <- bc_map %>% 
    group_by(variant) %>% 
    summarise(num_barcode = n())

var_stats_new %>% 
    ggplot(aes(num_barcode)) + geom_histogram(binwidth = 1) +
    labs(x = 'number of barcodes per variant')
```

```{r}
summary(var_stats_new$num_barcode)
```

```{r}
bc_map <- bc_map %>% 
    mutate(var_length = nchar(variant))

summary(bc_map$var_length)
```

```{r}
library(Biostrings)

var_stats_new <- var_stats_new %>% 
    mutate(var_length = nchar(variant))

ref <- ref %>% 
    mutate(original_seq = ifelse(grepl('flipped', name),
                                 as.character(reverseComplement(DNAStringSet(sequence))),
                                 sequence)) %>% 
    mutate(variant = substr(original_seq, 25, 174))


var_stats_in_ref <- semi_join(var_stats_new, ref, by = 'variant')
```

```{r}
ggplot(var_stats_in_ref, aes(num_barcode)) + geom_histogram(binwidth = 1) +
    labs(x = 'number of barcodes',
         title = 'consensus barcode mapper')
```

```{r}
summary(var_stats_in_ref$num_barcode)
```

```{r}
nrow(var_stats_in_ref) / nrow(ref)
```

```{r}
full_join(select(var_stats, variant, num_barcodes),
                 select(var_stats_in_ref, variant, num_consensus_barcodes = num_barcode),
                 by = 'variant') %>% 
    ggplot(aes(num_barcodes, num_consensus_barcodes)) + geom_point(alpha = 0.1) +
    geom_abline(slope = 1, intercept = 0) + 
    # scale_x_log10() + scale_y_log10() +
    coord_fixed() + theme(aspect.ratio=1) + xlim(c(0, 400)) + ylim(c(0, 400))
```

Let's see what the bad barcodes are from the consensus barcodes to see why there is such
discrepancy between the two mappers. Is my mapper mapping "bad" barcodes?

```{r}
bad_bcs <- read.table('bc-map_bad_bcs.txt', header = T, sep = ',')
```

```{r}
table(bad_bcs$reason)
```

```{r}
bad_overlap <- semi_join(bc_stats, bad_bcs, by = c('barcode' = 'bc'))
nrow(bad_overlap)
```

```{r}
bc_overlap <- semi_join(bc_stats, bc_map, by = 'barcode') %>% 
    left_join(select(bc_map, barcode, variant), by = 'barcode')

nrow(bc_overlap) / nrow(bc_stats)
```
 
 Hmm so most of the barcodes that I map also appear in the consensus mapper.
 
```{r}
(filter(bc_overlap, variant == most_common) %>% nrow() ) / nrow(bc_overlap)
```

Hmm so it seems the consensus mapper is getting most of the reference sequences 
since it has overlap with my mapper, which captures 99% of the library. I must
be joining with the reference incorrectly.

```{r}
semi_join(var_stats, ref, by ='variant') %>% nrow()
```

Hmm yea definitely checking wrong. In my mapper I check if the mapped variant
or the reverse complement is in the library. Let's just duplicate the library with
both versions of the sequence.

```{r}
ref_dup <- ref %>% 
    mutate(name = paste0(name, '_rc'),
           sequence = as.character(reverseComplement(DNAStringSet(sequence)))) %>% 
    select(name, sequence) %>% 
    bind_rows(select(ref, name, sequence)) %>% 
    mutate(variant = toupper(substr(sequence, 25, 174)))
```

```{r}
tmp <- anti_join(var_stats_new, ref_dup, by = 'variant') %>% 
    semi_join(bc_overlap, by = 'variant')
```

Realized my reference sequence has a mix of upper and lowercase!!

```{r}
var_stats_in_ref <- semi_join(var_stats_new, ref_dup, by = 'variant')
nrow(var_stats_in_ref) / nrow(ref)
```

Yay! 

```{r}
ggplot(var_stats_in_ref, aes(num_barcode)) + geom_histogram(binwidth = 1)
```

```{r}
summary(var_stats_in_ref$num_barcode)
```

```{r}
summary(var_stats$num_barcodes_unique)
```

Barcode distribution looks much better with consensus mapper than with my mapper.

Let's load the consensus mapping from the two combined mapping runs.

```
Mapping BCs...
Mapped 6675541 barcodes in 218.84 seconds
Filtering BCs without a consensus of < 3 reads
Found 3545853 BCs with < 3 reads in 17.84 secs
Using BBMap to find contaminated barcodes at 5 away
Mapped barcodes in 411.63 secs
Found 10840 barcodes that map too far away in 13.11 secs
Found 1114 truncated barcodes in 62.78 secs
Found 481 barcodes with at least one sequence at dist 4 with at least 2 reads in 24.31 secs
Merged reads in 222.29 seconds
Total BCs remaining after filters 3117253
Total time 16.18 mins
```

```{r}
bc_map_combined <- read.table('../../processed_data/endo_scramble/endo_scramble_combined_bc_map_consensus.txt',
                              header = F, sep = ',', col.names = c('barcode', 'variant', 'count'))
bc_map_combined %>% 
    group_by(variant) %>% 
    summarise(num_barcode = n()) %>% 
    semi_join(ref_dup, by = 'variant') %>% 
    summary(.$num_barcode)
```

Okay we got the median barcode up by 2 from combining runs!

Let's save the barcode map that only includes variants that are in the reference.


```{r}
# bc_map_ref <- semi_join(bc_map, ref_dup, by = 'variant')
bc_map_ref <- semi_join(bc_map_combined, ref_dup, by = 'variant')
bc_map_ref <- left_join(bc_map_ref, select(ref_dup, name, variant), by = 'variant')

write.table(bc_map_ref, '../../processed_data/endo_scramble/endo_scramble_combined_bc_map_consensus_ref.txt',
            row.names = F, sep = '\t', quote = F)
```

```{r}
length(unique(bc_map_ref$variant)) / nrow(ref)
```
